{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this routine want to evaluate the data record to find which dates are marked as heat waves by which of the different definitions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import routines and define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--- Libraries\n",
    "import matplotlib.pyplot as plt                      # plotting routines\n",
    "import seaborn as sns                                # more plotting routines\n",
    "import pandas as pd                                  # statistics packages\n",
    "import numpy  as np                                  # linear algebra packages\n",
    "import subprocess                                    # routines for calling external OS commands\n",
    "import datetime                                      # work with date objects\n",
    "import os.path                                       # more routines for working with external commands\n",
    "import time                                          # additional routines for working with dates/times\n",
    "\n",
    "from pandas.tseries.offsets import *                 # routines to modify time series labels\n",
    "from netCDF4 import Dataset                          # access NetCDF files\n",
    "from cdo import *                                    # routines for interacting with NetCDF files\n",
    "cdo = Cdo()                                          #                    via an external program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# place graphics in the notebook document\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#--- Identify regions of interest \n",
    "# choose country\n",
    "country = 'India'\n",
    "# read file of reported heatwaves\n",
    "heatwave_data = pd.read_csv('../data/Heatwaves_database.csv')\n",
    "heatwave_data.loc[heatwave_data.Region==' Tamil Nadu','Region'] = 'Tamil Nadu'\n",
    "#heatwave_data.Region[heatwave_data.Region==' Tamil Nadu'] = 'Tamil Nadu'\n",
    "# make list of unique region names for country\n",
    "regions = list( set(heatwave_data.Region.where(heatwave_data.Country==country)) )\n",
    "# remove nans (from regions that aren't in the selected country) \n",
    "regions = [x.title() for x in regions if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplfy implementation the definitions are applied to NetCDF files where all data that is not in the selected region has been masked out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/Orissa.mask.nc ../data/India.t2m.max.daily.subset.nc ../data/Orissa.max.daily.nc\n",
      "../data/Orissa.mask.nc ../data/India.t2m.min.daily.subset.nc ../data/Orissa.min.daily.nc\n",
      "../data/Orissa.mask.nc ../data/India.t2m.daily.subset.nc ../data/Orissa.daily.nc\n",
      "../data/Uttar_Pradesh.mask.nc ../data/India.t2m.max.daily.subset.nc ../data/Uttar_Pradesh.max.daily.nc\n",
      "../data/Uttar_Pradesh.mask.nc ../data/India.t2m.min.daily.subset.nc ../data/Uttar_Pradesh.min.daily.nc\n",
      "../data/Uttar_Pradesh.mask.nc ../data/India.t2m.daily.subset.nc ../data/Uttar_Pradesh.daily.nc\n",
      "../data/Tamil_Nadu.mask.nc ../data/India.t2m.max.daily.subset.nc ../data/Tamil_Nadu.max.daily.nc\n",
      "../data/Tamil_Nadu.mask.nc ../data/India.t2m.min.daily.subset.nc ../data/Tamil_Nadu.min.daily.nc\n",
      "../data/Tamil_Nadu.mask.nc ../data/India.t2m.daily.subset.nc ../data/Tamil_Nadu.daily.nc\n"
     ]
    }
   ],
   "source": [
    "#--- Apply mask\n",
    "# list data variabiles\n",
    "variables = [\"max.daily\",\"min.daily\",\"daily\"]\n",
    "# loop over regions\n",
    "for i in range(len(regions)) :\n",
    "    # create region name with no spaces\n",
    "    reg = \"_\".join(regions[i].split())\n",
    "    # loop over number of variables\n",
    "    for j in range(len(variables)) :\n",
    "        # choose variable\n",
    "        var = variables[j]\n",
    "        # identify regional mask\n",
    "        maskfile = \"../data/\"+reg+\".mask.nc\"\n",
    "        # identify file with data for given country\n",
    "        datafile = \"../data/\"+\"\".join(country.split(\" \"))+\".t2m.\"+var+\".subset.nc\"\n",
    "        # report files\n",
    "        print maskfile+\" \"+datafile,\n",
    "        print \"../data/\"+reg+\".\"+var+\".nc\"\n",
    "        # create mask file\n",
    "        _ = cdo.ifthen(input=maskfile+\" \"+datafile,\n",
    "                       output=\"../data/\"+reg+\".\"+var+\".nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat wave definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define functions that check the reanalysis data against each of the heat wave definitions. The goal is to create a sequence of 'event/not-event' (in a meteorological context) for the full time series that is considered. In the script the functions are labeled by the reference they are taken from, rathern than the more descriptive labels used in the texts (so to have variable names that don't include speical characters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Definition 1 [Fontaine et al 2013]:\n",
    "# Mean daily temperature > 90th percentile for 4 or more days\n",
    "# ============================================================\n",
    "def Fontaine (region,deflab) :\n",
    "    #--- Variables\n",
    "    thresh_temppctl = 90\n",
    "    seq_length  = 4\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( os.path.exists('../data/eventrec.\"+deflab+\".\"+region+\".nc') ) :\n",
    "        print(\"creating netcdf file\")\n",
    "        # calculate 90th percentiles for daily max temp\n",
    "        cdo.timmin(input = \"../data/\"+region+\".daily.nc\", output = \"../data/mindaily.nc\")\n",
    "        cdo.timmax(input = \"../data/\"+region+\".daily.nc\", output = \"../data/maxdaily.nc\")\n",
    "        cdo.timpctl(str(thresh_temppctl),\n",
    "                    input = \"../data/\"+region+\".daily.nc ../data/mindaily.nc ../data/maxdaily.nc \", \n",
    "                    output = \"../data/daily90.nc\")\n",
    "        # check each cell for > 90th percentile max temperature\n",
    "        cdo.gt(str(thresh_temppctl),\n",
    "               input = \"../data/\"+region+\".daily.nc ../data/daily90.nc\", \n",
    "               output = \"../data/gt90.nc\")\n",
    "        # do windowed sum, so that grid cell has value of 4 if that date, 2 days \n",
    "        #  before and day after are all 'true'\n",
    "        cdo.runsum(str(seq_length),\n",
    "                   input = \"../data/gt90.nc\", \n",
    "                   output = \"../data/eventsinwindow.nc\")\n",
    "        # check for events\n",
    "        cdo.gec(str(seq_length),\n",
    "                input = \"../data/eventsinwindow.nc\", \n",
    "                output = \"../data/prolongedevents.nc\")\n",
    "        # check for any events within region\n",
    "        #  NOTE: Since summing over a sliding window if a date is marked as an\n",
    "        #  event, then the 2 days before and day after are also events\n",
    "        cdo.fldmax(input = \"../data/prolongedevents.nc\", \n",
    "                   output = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "        # sweep up\n",
    "        subprocess.call([\"rm\",\"../data/mindaily.nc\",\"../data/maxdaily.nc\",\"../data/daily90.nc\",\n",
    "                         \"../data/gt90.nc\",\"../data/eventsinwindow.nc\",\"../data/prolongedevents.nc\"])\n",
    "  \n",
    "    #--- Generate time series data\n",
    "    # create variable from netcdf data\n",
    "    metrec = cdo.output(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert from unicode to integer\n",
    "    metrec = [int(x) for x in metrec]\n",
    "    # add values for dates omitted by windowed sum\n",
    "    for i in range(2) :\n",
    "        metrec.insert(0,int(0))\n",
    "    for i in range(1) :\n",
    "        metrec.insert(len(metrec),int(0))\n",
    "    # extend heatwave periods to account for windowed sum\n",
    "    tmp = metrec[:]\n",
    "    for i in range(2,(len(metrec)-1)) :\n",
    "        if ( metrec[i] == 1 ) & ( metrec[i-1] != 1 ) :\n",
    "            tmp[i-1] = 1 ; tmp[i-2] = 1\n",
    "        elif ( metrec[i] == 1 ) & ( metrec[i+1] != 1 ) :\n",
    "            tmp[i+1] = 1 \n",
    "    metrec = tmp\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # add 2 days to start of list (removed by windowed sum)\n",
    "    for i in range(2) :\n",
    "        day_alpha = dates[0] - Day()\n",
    "        dates = dates.insert(0,day_alpha)\n",
    "    # add 1 days to end of list (removed by windowed sum)\n",
    "    for i in range(1) :\n",
    "        day_omega = dates[len(dates)-1] + Day()\n",
    "        dates = dates.insert(len(dates),day_omega)\n",
    "    # returen time series data\n",
    "    ts = pd.Series(metrec, index=dates)\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating netcdf file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1969-12-31    0\n",
       "1970-01-01    0\n",
       "1970-01-02    0\n",
       "1970-01-03    0\n",
       "1970-01-04    0\n",
       "1970-01-05    0\n",
       "1970-01-06    0\n",
       "1970-01-07    0\n",
       "1970-01-08    0\n",
       "1970-01-09    0\n",
       "1970-01-10    0\n",
       "1970-01-11    0\n",
       "1970-01-12    0\n",
       "1970-01-13    0\n",
       "1970-01-14    0\n",
       "1970-01-15    0\n",
       "1970-01-16    0\n",
       "1970-01-17    0\n",
       "1970-01-18    0\n",
       "1970-01-19    0\n",
       "1970-01-20    0\n",
       "1970-01-21    0\n",
       "1970-01-22    0\n",
       "1970-01-23    0\n",
       "1970-01-24    0\n",
       "1970-01-25    0\n",
       "1970-01-26    0\n",
       "1970-01-27    0\n",
       "1970-01-28    0\n",
       "1970-01-29    0\n",
       "             ..\n",
       "2012-12-01    0\n",
       "2012-12-02    0\n",
       "2012-12-03    0\n",
       "2012-12-04    0\n",
       "2012-12-05    0\n",
       "2012-12-06    0\n",
       "2012-12-07    0\n",
       "2012-12-08    0\n",
       "2012-12-09    0\n",
       "2012-12-10    0\n",
       "2012-12-11    0\n",
       "2012-12-12    0\n",
       "2012-12-13    0\n",
       "2012-12-14    0\n",
       "2012-12-15    0\n",
       "2012-12-16    0\n",
       "2012-12-17    0\n",
       "2012-12-18    0\n",
       "2012-12-19    0\n",
       "2012-12-20    0\n",
       "2012-12-21    0\n",
       "2012-12-22    0\n",
       "2012-12-23    0\n",
       "2012-12-24    0\n",
       "2012-12-25    0\n",
       "2012-12-26    0\n",
       "2012-12-27    0\n",
       "2012-12-28    0\n",
       "2012-12-29    0\n",
       "2012-12-30    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fontaine('Orissa','Fountain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
