{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this routine evaluate the data record to find which dates are marked as heat waves by which of the different definitions. The analysis is done largely through calling the external program [CDO](https://code.zmaw.de/projects/cdo). There is a lot that is not ideal about this approach, and it is quite [duck tape style](http://www.joelonsoftware.com/items/2009/09/23.html). The pros of this approach are that it's very piece-wise, and so makes development and error checking easier. Hopefully the sequential logic of using these piece-wise operators create readable code. Also, since all the libraries, even those that callexternal programs, used in this example are available through [Anaconda](https://www.continuum.io/) it's possible to reproduce these examples without having to overly fine tune an individual computer. When you do so, ** please check the script for errors.** There inevitably are some. There is no attempt here to\n",
    "create a prescriptive and/or definitive routine. Just some people sitting up nights, trying to create simple sketches to illustrate common situations encountered in their various fields. Hoping that you want to be one of those people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import routines and define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--- Libraries\n",
    "import matplotlib.pyplot as plt                      # plotting routines\n",
    "import seaborn as sns                                # more plotting routines\n",
    "import pandas as pd                                  # statistics packages\n",
    "import numpy  as np                                  # linear algebra packages\n",
    "import subprocess                                    # routines for calling external OS commands\n",
    "import datetime                                      # work with date objects\n",
    "import os.path                                       # more routines for working with external commands\n",
    "import time                                          # additional routines for working with dates/times\n",
    "\n",
    "from pandas.tseries.offsets import *                 # routines to modify time series labels\n",
    "from netCDF4 import Dataset                          # access NetCDF files\n",
    "from cdo import *                                    # routines for interacting with NetCDF files\n",
    "cdo = Cdo()                                          #                    via an external program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# place graphics in the notebook document\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#--- Identify regions of interest \n",
    "# choose country\n",
    "country = 'India'\n",
    "# read file of reported heatwaves\n",
    "heatwave_data = pd.read_csv('../data/Heatwaves_database.csv')\n",
    "heatwave_data.loc[heatwave_data.Region==' Tamil Nadu','Region'] = 'Tamil Nadu'\n",
    "#heatwave_data.Region[heatwave_data.Region==' Tamil Nadu'] = 'Tamil Nadu'\n",
    "# make list of unique region names for country\n",
    "regions = list( set(heatwave_data.Region.where(heatwave_data.Country==country)) )\n",
    "# remove nans (from regions that aren't in the selected country) \n",
    "regions = [x.title() for x in regions if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplfy implementation the definitions are applied to NetCDF files where all data that is not in the selected region has been masked out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/Orissa.mask.nc ../data/India.t2m.max.daily.subset.nc ../data/Orissa.max.daily.nc\n",
      "../data/Orissa.mask.nc ../data/India.t2m.min.daily.subset.nc ../data/Orissa.min.daily.nc\n",
      "../data/Orissa.mask.nc ../data/India.t2m.daily.subset.nc ../data/Orissa.daily.nc\n",
      "../data/Uttar_Pradesh.mask.nc ../data/India.t2m.max.daily.subset.nc ../data/Uttar_Pradesh.max.daily.nc\n",
      "../data/Uttar_Pradesh.mask.nc ../data/India.t2m.min.daily.subset.nc ../data/Uttar_Pradesh.min.daily.nc\n",
      "../data/Uttar_Pradesh.mask.nc ../data/India.t2m.daily.subset.nc ../data/Uttar_Pradesh.daily.nc\n",
      "../data/Tamil_Nadu.mask.nc ../data/India.t2m.max.daily.subset.nc ../data/Tamil_Nadu.max.daily.nc\n",
      "../data/Tamil_Nadu.mask.nc ../data/India.t2m.min.daily.subset.nc ../data/Tamil_Nadu.min.daily.nc\n",
      "../data/Tamil_Nadu.mask.nc ../data/India.t2m.daily.subset.nc ../data/Tamil_Nadu.daily.nc\n",
      "../data/Orissa.mask.nc ../data/India.basefile.nc ../data/Orissa.max.daily.nc\n",
      "../data/Orissa.mask.nc ../data/India.basefile.nc ../data/Orissa.min.daily.nc\n",
      "../data/Orissa.mask.nc ../data/India.basefile.nc ../data/Orissa.daily.nc\n",
      "../data/Uttar_Pradesh.mask.nc ../data/India.basefile.nc ../data/Uttar_Pradesh.max.daily.nc\n",
      "../data/Uttar_Pradesh.mask.nc ../data/India.basefile.nc ../data/Uttar_Pradesh.min.daily.nc\n",
      "../data/Uttar_Pradesh.mask.nc ../data/India.basefile.nc ../data/Uttar_Pradesh.daily.nc\n",
      "../data/Tamil_Nadu.mask.nc ../data/India.basefile.nc ../data/Tamil_Nadu.max.daily.nc\n",
      "../data/Tamil_Nadu.mask.nc ../data/India.basefile.nc ../data/Tamil_Nadu.min.daily.nc\n",
      "../data/Tamil_Nadu.mask.nc ../data/India.basefile.nc ../data/Tamil_Nadu.daily.nc\n"
     ]
    }
   ],
   "source": [
    "#--- Apply mask\n",
    "# list data variabiles\n",
    "variables = [\"max.daily\",\"min.daily\",\"daily\"]\n",
    "# loop over regions\n",
    "for i in range(len(regions)) :\n",
    "    # create region name with no spaces\n",
    "    reg = \"_\".join(regions[i].split())\n",
    "    # loop over number of variables\n",
    "    for j in range(len(variables)) :\n",
    "        # choose variable\n",
    "        var = variables[j]\n",
    "        # identify regional mask\n",
    "        maskfile = \"../data/\"+reg+\".mask.nc\"\n",
    "        # identify file with data for given country\n",
    "        datafile = \"../data/\"+\"\".join(country.split(\" \"))+\".t2m.\"+var+\".subset.nc\"\n",
    "        # report files\n",
    "        print maskfile+\" \"+datafile,\n",
    "        print \"../data/\"+reg+\".\"+var+\".nc\"\n",
    "        # create mask file\n",
    "        _ = cdo.ifthen(input=maskfile+\" \"+datafile,\n",
    "                       output=\"../data/\"+reg+\".\"+var+\".nc\")\n",
    "\n",
    "# also mask the base period file\n",
    "# loop over regions\n",
    "for i in range(len(regions)) :\n",
    "    # create region name with no spaces\n",
    "    reg = \"_\".join(regions[i].split())\n",
    "    # loop over number of variables\n",
    "    for j in range(len(variables)) :\n",
    "        # choose variable\n",
    "        var = variables[j]\n",
    "        # identify regional mask\n",
    "        maskfile = \"../data/\"+reg+\".mask.nc\"\n",
    "        # identify file with data for given country\n",
    "        datafile = \"../data/\"+country+\".basefile.nc\"\n",
    "        # report files\n",
    "        print maskfile+\" \"+datafile,\n",
    "        print \"../data/\"+reg+\".\"+var+\".nc\"\n",
    "        # create mask file\n",
    "        _ = cdo.ifthen(input=maskfile+\" \"+datafile,\n",
    "                       output=\"../data/\"+reg+\".basefile.nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat wave definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define functions that check the reanalysis data against each of the heat wave definitions. The goal is to create a sequence of 'event/not-event' (in a meteorological context) for the full time series that is considered. In the script the functions are labeled by the reference they are taken from, rathern than the more descriptive labels used in the texts (so to have variable names that don't include speical characters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Definition: AveRel4 [Fontaine et al 2013]:\n",
    "# Mean daily temperature > 90th percentile for 4 or more days\n",
    "# ============================================================\n",
    "def Fontaine (region) :\n",
    "    #--- Variables\n",
    "    thresh_temppctl = 90\n",
    "    seq_length  = 4\n",
    "    deflab = 'Fontaine'\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( os.path.exists('../data/eventrec.\"+deflab+\".\"+region+\".nc') ) :\n",
    "        print(\"creating netcdf file\")\n",
    "        # calculate 90th percentiles for daily max temp\n",
    "        cdo.timmin(input = \"../data/\"+region+\".daily.nc\", output = \"../data/mindaily.nc\")\n",
    "        cdo.timmax(input = \"../data/\"+region+\".daily.nc\", output = \"../data/maxdaily.nc\")\n",
    "        cdo.timpctl(str(thresh_temppctl),\n",
    "                    input = \"../data/\"+region+\".daily.nc ../data/mindaily.nc ../data/maxdaily.nc \", \n",
    "                    output = \"../data/daily90.nc\")\n",
    "        # check each cell for > 90th percentile max temperature\n",
    "        cdo.gt(str(thresh_temppctl),\n",
    "               input = \"../data/\"+region+\".daily.nc ../data/daily90.nc\", \n",
    "               output = \"../data/gt90.nc\")\n",
    "        # do windowed sum, so that grid cell has value of 4 if that date, 2 days \n",
    "        #  before and day after are all 'true'\n",
    "        cdo.runsum(str(seq_length),\n",
    "                   input = \"../data/gt90.nc\", \n",
    "                   output = \"../data/eventsinwindow.nc\")\n",
    "        # check for events\n",
    "        cdo.gec(str(seq_length),\n",
    "                input = \"../data/eventsinwindow.nc\", \n",
    "                output = \"../data/prolongedevents.nc\")\n",
    "        # check for any events within region\n",
    "        #  NOTE: Since summing over a sliding window if a date is marked as an\n",
    "        #  event, then the 2 days before and day after are also events\n",
    "        cdo.fldmax(input = \"../data/prolongedevents.nc\", \n",
    "                   output = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "        # sweep up\n",
    "        subprocess.call([\"rm\",\"../data/mindaily.nc\",\"../data/maxdaily.nc\",\"../data/daily90.nc\",\n",
    "                         \"../data/gt90.nc\",\"../data/eventsinwindow.nc\",\"../data/prolongedevents.nc\"])\n",
    "  \n",
    "    #--- Generate time series data\n",
    "    # create variable from netcdf data\n",
    "    metrec = cdo.output(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert from unicode to integer\n",
    "    metrec = [int(x) for x in metrec]\n",
    "    # add values for dates omitted by windowed sum\n",
    "    for i in range(2) :\n",
    "        metrec.insert(0,int(0))\n",
    "    for i in range(1) :\n",
    "        metrec.insert(len(metrec),int(0))\n",
    "    # extend heatwave periods to account for windowed sum\n",
    "    tmp = metrec[:]\n",
    "    for i in range(2,(len(metrec)-1)) :\n",
    "        if ( metrec[i] == 1 ) & ( metrec[i-1] != 1 ) :\n",
    "            tmp[i-1] = 1 ; tmp[i-2] = 1\n",
    "        elif ( metrec[i] == 1 ) & ( metrec[i+1] != 1 ) :\n",
    "            tmp[i+1] = 1 \n",
    "    metrec = tmp\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # add 2 days to start of list (removed by windowed sum)\n",
    "    for i in range(2) :\n",
    "        day_alpha = dates[0] - Day()\n",
    "        dates = dates.insert(0,day_alpha)\n",
    "    # add 1 days to end of list (removed by windowed sum)\n",
    "    for i in range(1) :\n",
    "        day_omega = dates[len(dates)-1] + Day()\n",
    "        dates = dates.insert(len(dates),day_omega)\n",
    "    # returen time series data\n",
    "    ts = pd.Series(metrec, index=dates)\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Definition: AveRel2(mid) [Anderson and Bell, 2011; CAWCR, 2013]:\n",
    "# Mean daily temperature > 95th percentile for 2 or more days\n",
    "# ============================================================\n",
    "\n",
    "def Anderson (region) :\n",
    "    #--- Variables\n",
    "    thresh_temppctl = 95\n",
    "    seq_length  = 2\n",
    "    deflab = 'Anderson'\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( os.path.exists(\"../data/eventrec.\"+deflab+\".\"+region+\".nc\") ) :\n",
    "        print(\"creating netcdf file\")\n",
    "        ## calculate 90th percentiles for daily max temp\n",
    "        cdo.timmin(input = \"../data/\"+region+\".daily.nc\", output = \"../data/mindaily.nc\")\n",
    "        cdo.timmax(input = \"../data/\"+region+\".daily.nc\", output = \"../data/maxdaily.nc\")\n",
    "        cdo.timpctl(str(thresh_temppctl),\n",
    "                    input = \"../data/\"+region+\".daily.nc ../data/mindaily.nc ../data/maxdaily.nc \", \n",
    "                    output = \"../data/daily95.nc\")\n",
    "        ## check each cell for > 90th percentile max temperature\n",
    "        cdo.gt(str(thresh_temppctl),\n",
    "               input = \"../data/\"+region+\".daily.nc ../data/daily95.nc\", \n",
    "               output = \"../data/gt95.nc\")\n",
    "        ## Do windowed sum, so that grid cell has value of 2 if that date, and 1 day\n",
    "        #  before are all 'true'\n",
    "        cdo.runsum(str(seq_length),\n",
    "                   input = \"../data/gt95.nc\", \n",
    "                   output = \"../data/eventsinwindow.nc\")\n",
    "        ## Check for events\n",
    "        cdo.gec(str(seq_length),\n",
    "                input = \"../data/eventsinwindow.nc\", \n",
    "                output = \"../data/prolongedevents.nc\")\n",
    "        ## Check for any events within region\n",
    "        #  NOTE: Since summing over a sliding window if a date is marked as an\n",
    "        #  event, then the day before is also an event\n",
    "        cdo.fldmax(input = \"../data/prolongedevents.nc\", \n",
    "                   output = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## Sweep up\n",
    "        subprocess.call([\"rm\",\"../data/mindaily.nc\",\"../data/maxdaily.nc\",\"../data/daily95.nc\",\n",
    "                         \"../data/gt95.nc\",\"../data/eventsinwindow.nc\",\"../data/prolongedevents.nc\"])\n",
    "    #--- Generate time series data\n",
    "    # create variable from netcdf data\n",
    "    metrec = cdo.output(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert from unicode to integer\n",
    "    metrec = [int(x) for x in metrec]\n",
    "    # add values for dates omitted by windowed sum\n",
    "    for i in range(1) :\n",
    "        metrec.insert(0,int(0))\n",
    "    # for i in range(1) :\n",
    "    #     metrec.insert(len(metrec),int(0))\n",
    "    # extend heatwave periods to account for windowed sum\n",
    "    tmp = metrec[:]\n",
    "    for i in range(1,(len(metrec)-1)) :\n",
    "        if ( metrec[i] == 1 ) & ( metrec[i-1] != 1 ) :\n",
    "            tmp[i-1] = 1 \n",
    "        # elif ( metrec[i] == 1 ) & ( metrec[i+1] != 1 ) :\n",
    "        #     tmp[i+1] = 1 \n",
    "    metrec = tmp\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # add 1 day to start of list (removed by windowed sum)\n",
    "    for i in range(1) :\n",
    "        day_alpha = dates[0] - Day()\n",
    "        dates = dates.insert(0,day_alpha)\n",
    "    #--- Returen time series data\n",
    "    ts = pd.Series(metrec, index=dates)\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Definition AveRel3+ [Peng et al., 2001]\n",
    "# Every portion of sequences of days with daily mean over the 81st\n",
    "# percentile where at least 3 of those days is above the 97.5th\n",
    "# percentile, and the average of that portion is above the 97.5th\n",
    "# percentile.\n",
    "# ================================================================\n",
    "def Peng (region) :\n",
    "    #--- Variables\n",
    "    deflab = 'Peng'\n",
    "    #--- Read data\n",
    "    ## Load temperature variable directly into python\n",
    "    # open data file\n",
    "    fh = Dataset(\"../data/\"+region+\".daily.nc\")\n",
    "    # pull in temperature variable\n",
    "    v = fh.variables['air'][:]\n",
    "    # close data file\n",
    "    fh.close()\n",
    "    # take dates from data file\n",
    "    dates = cdo.showdate(input = \"../data/\"+region+\".daily.nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    #--- List flagged time-indexes (for all grid cells)\n",
    "    # save results\n",
    "    matches = []\n",
    "    # predeclare some variables that get overwritten in the loop \n",
    "    qualified_sequences = []\n",
    "    potential_seq = []\n",
    "    # loop through grid cells\n",
    "    for i in range(v.shape[1]) :\n",
    "        for j in range(v.shape[2]) :\n",
    "            if not v[0,i,j] is np.ma.masked :\n",
    "                # example sequance of value \n",
    "                x = pd.Series(v[:,i,j])\n",
    "                # estimate threshold values \n",
    "                T1,T2 = x.quantile(0.81),x.quantile(0.975)\n",
    "                # create list of all indexes that meet all the criteria\n",
    "                qualified_sequences = []\n",
    "                # print i,j \n",
    "                for m in range(len(x)) :\n",
    "                    # print m\n",
    "                    # create list of indexes that meet first criteria\n",
    "                    potential_seq = []\n",
    "                    n = m\n",
    "                    # check that value meets first criteria\n",
    "                    while ( (x[n] > T1) & ( n < (len(x)-1)) ) :\n",
    "                        potential_seq.append(n)\n",
    "                        # if meets remaining criteria\n",
    "                        if ( (sum(x[potential_seq] > T2) >=3) & (x[potential_seq].mean() > T2) ) :\n",
    "                            # then note this sequence\n",
    "                            qualified_sequences.extend(potential_seq)\n",
    "                        # extend sequence\n",
    "                        n += 1\n",
    "            # keep record of indexes in the qualified sequences\n",
    "            matches.extend(sorted(set(qualified_sequences)))\n",
    "    ts = pd.Series(0,index=dates)\n",
    "    ts[dates[sorted(list(set(matches)))]] = 1\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Definition: MaxAbs3 [Hansen et al. 2008]:\n",
    "# Max temperature greater than 35degC for 3 or more days\n",
    "# =======================================================================\n",
    "def Hansen(region) :\n",
    "    #--- Variables \n",
    "    deflab = 'Hansen'\n",
    "    thresh_temp = 35+273\n",
    "    seq_length  = 3\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( os.path.exists(\"../data/eventrec.\"+deflab+\".\"+region+\".nc\") ) :\n",
    "        print(\"creating netcdf file\")\n",
    "        ## check each cell for >= 25degC\n",
    "        cdo.gtc(str(thresh_temp),\n",
    "                input = \"../data/\"+region+\".max.daily.nc\", \n",
    "                output = \"../data/tmp00.nc\")\n",
    "        ## Do windowed sum, so that grid cell has value of 3 if that date, day\n",
    "        #  before and day after are all 'true'\n",
    "        cdo.runsum(str(seq_length),\n",
    "                   input = \"../data/tmp00.nc\", \n",
    "                   output = \"../data/tmp01.nc\")\n",
    "        ## Check for events\n",
    "        cdo.gec(str(seq_length),\n",
    "                input = \"../data/tmp01.nc\", \n",
    "                output = \"../data/tmp02.nc\")\n",
    "        ## Check for any events within region\n",
    "        #  NOTE: Since summing over a sliding window if a date is marked as an\n",
    "        #  event, then the day before and day after are also events\n",
    "        cdo.fldmax(input = \"../data/tmp02.nc\", \n",
    "                   output = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## Sweep up\n",
    "        subprocess.call([\"rm\",\"../data/tmp00.nc\",\"../data/tmp01.nc\",\"../data/tmp02.nc\"])\n",
    "    #--- Generate time series data\n",
    "    # create variable from netcdf data\n",
    "    metrec = cdo.output(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert from unicode to integer\n",
    "    metrec = [int(x) for x in metrec]\n",
    "    # add values for dates ommited by windowed sum\n",
    "    metrec.insert(0,int(0))\n",
    "    metrec.insert(len(metrec),int(0))\n",
    "    # extend heatwave periods to account for windowed sum\n",
    "    tmp = metrec[:]\n",
    "    for i in range(1,(len(metrec)-1)) :\n",
    "        if ( metrec[i] == 1 ) & ( metrec[i-1] != 1 ) :\n",
    "            tmp[i-1] = 1\n",
    "        elif ( metrec[i] == 1 ) & ( metrec[i+1] != 1 ) :\n",
    "            tmp[i+1] = 1\n",
    "    metrec = tmp\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # add one day to start of list (removed by windowed sum)\n",
    "    day_alpha = dates[0] - Day()\n",
    "    dates = dates.insert(0,day_alpha)\n",
    "    # add one day to end of list (removed by windowed sum)\n",
    "    day_omega = dates[len(dates)-1] + Day()\n",
    "    dates = dates.insert(len(dates),day_omega)\n",
    "    #--- returen time series data\n",
    "    ts = pd.Series(metrec, index=dates)\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Definition: AveRel2(high) [Kent et al. 2014]:\n",
    "# Mean daily temperature > 98th percentile for 2 or more days\n",
    "# =============================================================================\n",
    "def Kent_high(region) :\n",
    "    #--- variables\n",
    "    deflab = 'Kent_high'\n",
    "    thresh_temppctl = 98\n",
    "    seq_length  = 2\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( os.path.exists(\"../data/eventrec.\"+deflab+\".\"+region+\".nc\") ) :\n",
    "        print(\"creating netcdf file\")\n",
    "        ## calculate 90th percentiles for daily max temp\n",
    "        cdo.timmin(input = \"../data/\"+region+\".daily.nc\", \n",
    "                   output = \"../data/mindaily.nc\")\n",
    "        cdo.timmax(input = \"../data/\"+region+\".daily.nc\", \n",
    "                   output = \"../data/maxdaily.nc\")\n",
    "        cdo.timpctl(str(thresh_temppctl),\n",
    "                    input = \"../data/\"+region+\".daily.nc ../data/mindaily.nc ../data/maxdaily.nc \", \n",
    "                    output = \"../data/daily95.nc\")\n",
    "        ## check each cell for > 90th percentile max temperature\n",
    "        cdo.gt(str(thresh_temppctl),\n",
    "               input = \"../data/\"+region+\".daily.nc ../data/daily95.nc\", \n",
    "               output = \"../data/gt95.nc\")\n",
    "        ## Do windowed sum, so that grid cell has value of 2 if that date, and 1 day\n",
    "        #  before are all 'true'\n",
    "        cdo.runsum(str(seq_length),\n",
    "                   input = \"../data/gt95.nc\", \n",
    "                   output = \"../data/eventsinwindow.nc\")\n",
    "        ## Check for events\n",
    "        cdo.gec(str(seq_length),\n",
    "                input = \"../data/eventsinwindow.nc\", \n",
    "                output = \"../data/prolongedevents.nc\")\n",
    "        ## Check for any events within region\n",
    "        #  NOTE: Since summing over a sliding window if a date is marked as an\n",
    "        #  event, then the day before is also an event\n",
    "        cdo.fldmax(input = \"../data/prolongedevents.nc\", \n",
    "                   output = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## Sweep up\n",
    "        subprocess.call([\"rm\",\"../data/mindaily.nc\",\"../data/maxdaily.nc\",\"../data/daily95.nc\",\n",
    "                         \"../data/gt95.nc\",\"../data/eventsinwindow.nc\",\n",
    "                         \"../data/prolongedevents.nc\"])\n",
    "    #--- Generate time series data\n",
    "    # create variable from netcdf data\n",
    "    metrec = cdo.output(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert from unicode to integer\n",
    "    metrec = [int(x) for x in metrec]\n",
    "    # add values for dates omitted by windowed sum\n",
    "    for i in range(1) :\n",
    "        metrec.insert(0,int(0))\n",
    "    # for i in range(1) :\n",
    "    #     metrec.insert(len(metrec),int(0))\n",
    "    # extend heatwave periods to account for windowed sum\n",
    "    tmp = metrec[:]\n",
    "    for i in range(1,(len(metrec)-1)) :\n",
    "        if ( metrec[i] == 1 ) & ( metrec[i-1] != 1 ) :\n",
    "            tmp[i-1] = 1 \n",
    "        # elif ( metrec[i] == 1 ) & ( metrec[i+1] != 1 ) :\n",
    "        #     tmp[i+1] = 1 \n",
    "    metrec = tmp\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # add 1 day to start of list (removed by windowed sum)\n",
    "    for i in range(1) :\n",
    "        day_alpha = dates[0] - Day()\n",
    "        dates = dates.insert(0,day_alpha)\n",
    "    # # add 1 days to end of list (removed by windowed sum)\n",
    "    # for i in range(1) :\n",
    "    #     day_omega = dates[len(dates)-1] + Day()\n",
    "    #     dates = dates.insert(len(dates),day_omega)\n",
    "    #--- returen time series data\n",
    "    ts = pd.Series(metrec, index=dates)\n",
    "    return ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# Definition: AvgRel2(low)  [Kent et al. 2014]:\n",
    "# Mean daily temperature > 90th percentile for 2 or more days\n",
    "# ========================================================================\n",
    "def Kent_low (region) :\n",
    "    #--- Variables\n",
    "    deflab = 'Kent_low'\n",
    "    thresh_temppctl = 90\n",
    "    seq_length  = 2\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( os.path.exists(\"data/eventrec.\"+deflab+\".\"+region+\".nc\") ) :\n",
    "        print(\"creating netcdf file\")\n",
    "        ## calculate 90th percentiles for daily max temp\n",
    "        cdo.timmin(input = \"../data/\"+region+\".daily.nc\", \n",
    "                   output = \"../data/mindaily.nc\")\n",
    "        cdo.timmax(input = \"../data/\"+region+\".daily.nc\", \n",
    "                   output = \"../data/maxdaily.nc\")\n",
    "        cdo.timpctl(str(thresh_temppctl),\n",
    "                    input = \"../data/\"+region+\".daily.nc ../data/mindaily.nc ../data/maxdaily.nc \", \n",
    "                    output = \"../data/daily95.nc\")\n",
    "        ## check each cell for > 90th percentile max temperature\n",
    "        cdo.gt(str(thresh_temppctl),\n",
    "               input = \"../data/\"+region+\".daily.nc ../data/daily95.nc\", \n",
    "               output = \"../data/gt95.nc\")\n",
    "        ## Do windowed sum, so that grid cell has value of 2 if that date, and 1 day\n",
    "        #  before are all 'true'\n",
    "        cdo.runsum(str(seq_length),input = \"../data/gt95.nc\", \n",
    "                   output = \"../data/eventsinwindow.nc\")\n",
    "        ## Check for events\n",
    "        cdo.gec(str(seq_length),\n",
    "                input = \"../data/eventsinwindow.nc\", \n",
    "                output = \"../data/prolongedevents.nc\")\n",
    "        ## Check for any events within region\n",
    "        #  NOTE: Since summing over a sliding window if a date is marked as an\n",
    "        #  event, then the day before is also an event\n",
    "        cdo.fldmax(input = \"../data/prolongedevents.nc\", \n",
    "                   output = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## Sweep up\n",
    "        subprocess.call([\"rm\",\"../data/mindaily.nc\",\"../data/maxdaily.nc\",\"../data/daily95.nc\",\n",
    "                         \"../data/gt95.nc\",\"../data/eventsinwindow.nc\",\"../data/prolongedevents.nc\"])\n",
    "    #--- Generate time series data\n",
    "    # create variable from netcdf data\n",
    "    metrec = cdo.output(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert from unicode to integer\n",
    "    metrec = [int(x) for x in metrec]\n",
    "    # add values for dates omitted by windowed sum\n",
    "    for i in range(1) :\n",
    "        metrec.insert(0,int(0))\n",
    "    # for i in range(1) :\n",
    "    #     metrec.insert(len(metrec),int(0))\n",
    "    # extend heatwave periods to account for windowed sum\n",
    "    tmp = metrec[:]\n",
    "    for i in range(1,(len(metrec)-1)) :\n",
    "        if ( metrec[i] == 1 ) & ( metrec[i-1] != 1 ) :\n",
    "            tmp[i-1] = 1 \n",
    "        # elif ( metrec[i] == 1 ) & ( metrec[i+1] != 1 ) :\n",
    "        #     tmp[i+1] = 1 \n",
    "    metrec = tmp\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # add 1 day to start of list (removed by windowed sum)\n",
    "    for i in range(1) :\n",
    "        day_alpha = dates[0] - Day()\n",
    "        dates = dates.insert(0,day_alpha)\n",
    "    # # add 1 days to end of list (removed by windowed sum)\n",
    "    # for i in range(1) :\n",
    "    #     day_omega = dates[len(dates)-1] + Day()\n",
    "    #     dates = dates.insert(len(dates),day_omega)\n",
    "    #--- returen time series data\n",
    "    ts = pd.Series(metrec, index=dates)\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Definition: MaxAbs2 [Tan et al. 2003]:\n",
    "# Max temperature greater than 35degC for 2 or more days\n",
    "# =======================================================================\n",
    "def Tan(region) :\n",
    "    #--- Variables\n",
    "    deflab = 'Tan'\n",
    "    thresh_temp = 35+273\n",
    "    seq_length  = 2\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( os.path.exists(\"../data/eventrec.\"+deflab+\".\"+region+\".nc\") ) :\n",
    "        print(\"creating netcdf file\")\n",
    "        ## check each cell for >= 35degC\n",
    "        cdo.gtc(str(thresh_temp),\n",
    "                input = \"../data/\"+region+\".max.daily.nc\", \n",
    "                output = \"../data/tmp00.nc\")\n",
    "        ## Do windowed sum, so that grid cell has value of 2 if that date, \n",
    "        #  and day after are all 'true'\n",
    "        cdo.runsum(str(seq_length),\n",
    "                   input = \"../data/tmp00.nc\", \n",
    "                   output = \"../data/tmp01.nc\")\n",
    "        ## Check for events\n",
    "        cdo.gec(str(seq_length),\n",
    "                input = \"../data/tmp01.nc\", \n",
    "                output = \"../data/tmp02.nc\")\n",
    "        ## Check for any events within region\n",
    "        #  NOTE: Since summing over a sliding window if a date is marked as an\n",
    "        #  event, then the day after is also an event\n",
    "        cdo.fldmax(input = \"../data/tmp02.nc\", \n",
    "                   output = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## Sweep up\n",
    "        subprocess.call([\"rm\",\"../data/tmp00.nc\",\"../data/tmp01.nc\",\"../data/tmp02.nc\"])\n",
    "    #--- Generate time series data\n",
    "    # create variable from netcdf data\n",
    "    metrec = cdo.output(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert from unicode to integer\n",
    "    metrec = [int(x) for x in metrec]\n",
    "    # add values for dates omitted by windowed sum\n",
    "    # for i in range(1) :\n",
    "    #     metrec.insert(0,int(0))\n",
    "    for i in range(1) :\n",
    "        metrec.insert(len(metrec),int(0))\n",
    "    # extend heatwave periods to account for windowed sum\n",
    "    tmp = metrec[:]\n",
    "    for i in range(1,(len(metrec)-1)) :\n",
    "        if ( metrec[i] == 1 ) & ( metrec[i+1] != 1 ) :\n",
    "            tmp[i+1] = 1 \n",
    "    metrec = tmp\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # # add one day to start of list (removed by windowed sum)\n",
    "    # day_alpha = dates[0] - Day()\n",
    "    # dates = dates.insert(0,day_alpha)\n",
    "    # add one day to end of list (removed by windowed sum)\n",
    "    day_omega = dates[len(dates)-1] + Day()\n",
    "    dates = dates.insert(len(dates),day_omega)\n",
    "    #--- set data as time series \n",
    "    x = pd.Series(metrec, index=dates)\n",
    "    #--- only consider values between June 15th and September 15th\n",
    "    x.ix[ (x.index.month < 6) | (x.index.month > 9) ] = 0\n",
    "    x.ix[ (x.index.month == 6) & (x.index.day < 15) ] = 0\n",
    "    x.ix[ (x.index.month == 9) & (x.index.day > 15) ] = 0\n",
    "    ts = x\n",
    "    #--- returen time series data\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Definition: MaxRel1(low) [Indian Meteorological Department]:\n",
    "# Any day that is > 5degC above daily climatology when the\n",
    "# climatological value is 40degC or below, or any day that is >\n",
    "# 4degC above daily climatology when climatological value is above\n",
    "# 40degC, or any day that is above 45degC. \n",
    "# =============================================================\n",
    "def IMD(region) :\n",
    "    #--- Variables \n",
    "    deflab = 'IMD'\n",
    "    thresh_annom_leq40 = 5\n",
    "    thresh_annom_gt40  = 4\n",
    "    thresh_tmp         = 45+273\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( (os.path.exists(\"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")) & (os.path.exists(\"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")) & (os.path.exists(\"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")) ) :\n",
    "        print(\"creating netcdf file\")\n",
    "        ## calculate daily climatology of max temperatures\n",
    "        cdo.ydaymean(input=\"../data/\"+region+\".max.daily.nc\",\n",
    "                     output=\"../data/clim.nc\")\n",
    "        ## calculate anomaly from daily climatology\n",
    "        cdo.sub(input=\"../data/\"+region+\".max.daily.nc ../data/clim.nc\", \n",
    "                output=\"../data/annom.nc\")\n",
    "        ## see when/where annom is greater than 5\n",
    "        cdo.gtc(str(thresh_annom_leq40),\n",
    "                input = \"../data/annom.nc\", \n",
    "                output = \"../data/a_gt5.nc\")\n",
    "        ## see when/where annom is greater than 4\n",
    "        cdo.gtc(str(thresh_annom_gt40),\n",
    "                input = \"../data/annom.nc\", \n",
    "                output = \"../data/a_gt4.nc\")\n",
    "        # create long term climatology file\n",
    "        cdo.setrtoc(\"-100,100,0\",\n",
    "                    input=\"../data/annom.nc\",\n",
    "                    output=\"../data/fullnull.nc\")\n",
    "        cdo.add(input=\"../data/fullnull.nc ../data/clim.nc\",\n",
    "                output=\"../data/clim.extnd.nc\")\n",
    "        ## see when/where max temp is <= 40\n",
    "        cdo.lec(str(273+40),\n",
    "                input=\"../data/clim.extnd.nc\", \n",
    "                output=\"../data/c_le40.nc\")\n",
    "        ## see when/where max temp is > 40\n",
    "        cdo.gtc(str(273+40),\n",
    "                input=\"../data/clim.extnd.nc\", \n",
    "                output=\"../data/c_gt40.nc\")\n",
    "        ## only consider annom > 5 when clim <= 40\n",
    "        cdo.ifthen(input=\"../data/c_le40.nc ../data/a_gt5.nc\",\n",
    "                   output=\"../data/conditionA.nc\")\n",
    "        cdo.fldmax(input = \"../data/conditionA.nc\", \n",
    "                   output = \"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## only consider annom > 4 when clim > 40 \n",
    "        cdo.ifthen(input=\"../data/c_gt40.nc ../data/a_gt4.nc\",\n",
    "                   output=\"../data/conditionB.nc\")\n",
    "        cdo.fldmax(input = \"../data/conditionB.nc\", \n",
    "                   output = \"../data/eventrecB.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## see when/where max temp is > 45\n",
    "        cdo.gtc(str(273+45),\n",
    "                input=\"../data/\"+region+\".max.daily.nc\",\n",
    "                output=\"../data/conditionC.nc\")\n",
    "        cdo.fldmax(input = \"../data/conditionC.nc\", \n",
    "                   output = \"../data/eventrecC.\"+deflab+\".\"+region+\".nc\")\n",
    "        subprocess.call([\"rm\",\"../data/clim.nc\",\"../data/annom.nc\",\"../data/a_gt5.nc\",\"../data/a_gt4.nc\",\n",
    "                         \"../data/fullnull.nc\",\"../data/clim.extnd.nc\",\n",
    "                         \"../data/c_le40.nc\",\"../data/c_gt40.nc\",\n",
    "                         \"../data/conditionA.nc\",\"../data/conditionB.nc\",\"../data/conditionC.nc\"])\n",
    "    #--- Generate time series data\n",
    "    ## create variable from netcdf data\n",
    "    # read netcdf file\n",
    "    metrec_a = cdo.output(input = \"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert elements to integers \n",
    "    metrec_a = [int(x) for x in metrec_a]\n",
    "    # read netcdf file\n",
    "    metrec_b = cdo.output(input = \"../data/eventrecB.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert to floats\n",
    "    metrec_b = [float(x) for x in metrec_b]\n",
    "    # set as array\n",
    "    metrec_b = np.array(metrec_b)\n",
    "    # find indexes of missing values\n",
    "    ind_nan = (np.where(metrec_b < 0 )[0])\n",
    "    # set missing values as null\n",
    "    metrec_b[ind_nan] = 0\n",
    "    # set as integers\n",
    "    metrec_b = [int(x) for x in metrec_b]\n",
    "    # read data from netcdf file\n",
    "    metrec_c = cdo.output(input = \"../data/eventrecC.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert to floats\n",
    "    metrec_c = [float(x) for x in metrec_c]\n",
    "    # set as array\n",
    "    metrec_c = np.array(metrec_c)\n",
    "    # find indexes of missing values\n",
    "    ind_nan = (np.where(metrec_c < 0 )[0])\n",
    "    # set missing values as null\n",
    "    metrec_c[ind_nan] = 0\n",
    "    # set as integers\n",
    "    metrec_c = [int(x) for x in metrec_c]\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # create time series\n",
    "    metrec_a = pd.Series(metrec_a, index=dates)\n",
    "    metrec_b = pd.Series(metrec_b, index=dates)\n",
    "    metrec_c = pd.Series(metrec_c, index=dates)    \n",
    "    # combine series\n",
    "    metrec = metrec_a + metrec_b + metrec_c\n",
    "    # set so that max is 1\n",
    "    ind_multievent = (np.where(metrec > 1 )[0])\n",
    "    metrec[ind_multievent] = 1\n",
    "    ts = metrec\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# Definition: MaxRel1(high) [Indian Meteorological Department]:\n",
    "# Any day that is > 7degC above daily climatology when the\n",
    "# climatological value is 40degC or below, or any day that is >\n",
    "# 6degC above daily climatology when climatological value is above\n",
    "# 40degC, or any day that is above 45degC. \n",
    "# =====================================================================================\n",
    "def IMD_severe(region) :\n",
    "    #--- Variables\n",
    "    deflab = 'IMD_severe'\n",
    "    thresh_annom_leq40 = 7\n",
    "    thresh_annom_gt40  = 6\n",
    "    thresh_tmp         = 45+273\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( (os.path.exists(\"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")) | (os.path.exists(\"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")) | (os.path.exists(\"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")) ) :\n",
    "        print(\"creating netcdf file\")\n",
    "        ## calculate daily climatology of max temperatures\n",
    "        cdo.ydaymean(input=\"../data/\"+region+\".max.daily.nc\",\n",
    "                     output=\"../data/clim.nc\")\n",
    "        ## calculate anomaly from daily climatology\n",
    "        cdo.sub(input=\"../data/\"+region+\".max.daily.nc ../data/clim.nc\", \n",
    "                output=\"../data/annom.nc\")\n",
    "        ## see when/where annom is greater than 5\n",
    "        cdo.gtc(str(thresh_annom_leq40),\n",
    "                input = \"../data/annom.nc\", \n",
    "                output = \"../data/a_gt5.nc\")\n",
    "        ## see when/where annom is greater than 4\n",
    "        cdo.gtc(str(thresh_annom_gt40),\n",
    "                input = \"../data/annom.nc\", \n",
    "                output = \"../data/a_gt4.nc\")\n",
    "        # create long term climatology file\n",
    "        cdo.setrtoc(\"-100,100,0\",\n",
    "                    input=\"../data/annom.nc\",\n",
    "                    output=\"../data/fullnull.nc\")\n",
    "        cdo.add(input=\"../data/fullnull.nc ../data/clim.nc\",\n",
    "                output=\"../data/clim.extnd.nc\")\n",
    "        ## see when/where max temp is <= 40\n",
    "        cdo.lec(str(273+40),\n",
    "                input=\"../data/clim.extnd.nc\", \n",
    "                output=\"../data/c_le40.nc\")\n",
    "        ## see when/where max temp is > 40\n",
    "        cdo.gtc(str(273+40),\n",
    "                input=\"../data/clim.extnd.nc\", \n",
    "                output=\"../data/c_gt40.nc\")\n",
    "        ## only consider annom > 5 when clim <= 40\n",
    "        cdo.ifthen(input=\"../data/c_le40.nc ../data/a_gt5.nc\",\n",
    "                   output=\"../data/conditionA.nc\")\n",
    "        cdo.fldmax(input = \"../data/conditionA.nc\", \n",
    "                   output = \"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## only consider annom > 4 when clim > 40 \n",
    "        cdo.ifthen(input=\"../data/c_gt40.nc ../data/a_gt4.nc\",\n",
    "                   output=\"../data/conditionB.nc\")\n",
    "        cdo.fldmax(input = \"../data/conditionB.nc\", \n",
    "                   output = \"../data/eventrecB.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## see when/where max temp is > 45\n",
    "        cdo.gtc(str(273+45),\n",
    "                input=\"../data/\"+region+\".max.daily.nc\",\n",
    "                output=\"../data/conditionC.nc\")\n",
    "        cdo.fldmax(input = \"../data/conditionC.nc\", \n",
    "                   output = \"../data/eventrecC.\"+deflab+\".\"+region+\".nc\")\n",
    "        subprocess.call([\"rm\",\"../data/clim.nc\",\"../data/annom.nc\",\"../data/a_gt5.nc\",\n",
    "                         \"../data/a_gt4.nc\",\"../data/fullnull.nc\",\"../data/clim.extnd.nc\",\n",
    "                         \"../data/c_le40.nc\",\"../data/c_gt40.nc\",\"../data/conditionA.nc\",\n",
    "                         \"../data/conditionB.nc\",\"../data/conditionC.nc\"])\n",
    "    #--- Generate time series data\n",
    "    ## create variable from netcdf data\n",
    "    # read netcdf file\n",
    "    metrec_a = cdo.output(input = \"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert elements to integers \n",
    "    metrec_a = [int(x) for x in metrec_a]\n",
    "    # read netcdf file\n",
    "    metrec_b = cdo.output(input = \"../data/eventrecB.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert to floats\n",
    "    metrec_b = [float(x) for x in metrec_b]\n",
    "    # set as array\n",
    "    metrec_b = np.array(metrec_b)\n",
    "    # find indexes of missing values\n",
    "    ind_nan = (np.where(metrec_b < 0 )[0])\n",
    "    # set missing values as null\n",
    "    metrec_b[ind_nan] = 0\n",
    "    # set as integers\n",
    "    metrec_b = [int(x) for x in metrec_b]\n",
    "    # read data from netcdf file\n",
    "    metrec_c = cdo.output(input = \"../data/eventrecC.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert to floats\n",
    "    metrec_c = [float(x) for x in metrec_c]\n",
    "    # set as array\n",
    "    metrec_c = np.array(metrec_c)\n",
    "    # find indexes of missing values\n",
    "    ind_nan = (np.where(metrec_c < 0 )[0])\n",
    "    # set missing values as null\n",
    "    metrec_c[ind_nan] = 0\n",
    "    # set as integers\n",
    "    metrec_c = [int(x) for x in metrec_c]\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrecA.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # create time series\n",
    "    metrec_a = pd.Series(metrec_a, index=dates)\n",
    "    metrec_b = pd.Series(metrec_b, index=dates)\n",
    "    metrec_c = pd.Series(metrec_c, index=dates)    \n",
    "    # combine series\n",
    "    metrec = metrec_a + metrec_b + metrec_c\n",
    "    # set so that max is 1\n",
    "    ind_multievent = (np.where(metrec > 1 )[0])\n",
    "    metrec[ind_multievent] = 1\n",
    "    ts = metrec\n",
    "    return ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'base period' files for the different regions were created perviously, as part of the script `india_map.ipynb`, as the retained reanalysis data files cover only the range of dates addressed by the Desinvitar data base, and so do not cover the full range of the base period prescribed by the WMO, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Definition: MaxRel6 [ ECA Warm Spell duration index ]:\n",
    "# Sequences of 6 days above the 90th percentile of a base peried\n",
    "# (1960-1990) where the percentile for a given date is given by\n",
    "# considering it the center of a 5 day window. \n",
    "# =========================================================================\n",
    "def WSDI(region) :\n",
    "    #--- Variables\n",
    "    deflab = 'WSDI'\n",
    "    thresh_maxtemppctl = 90\n",
    "    seq_length  = 6\n",
    "    #--- Create netcdf file based on criteria, if doesn't already exist\n",
    "    if not ( (os.path.exists(\"../data/eventrec.\"+deflab+\".\"+region+\".nc\")) ):\n",
    "        print(\"creating netcdf file\")\n",
    "        ## identify original file\n",
    "        dfile = '../data/'+region+'.max.daily.nc'\n",
    "        ### create boot strap estimates of percentile levels\n",
    "        #   leaving out each year in turn\n",
    "        for oob_yr in range(1961,1988) :\n",
    "            print oob_yr\n",
    "            # create list of initial part of sequence\n",
    "            yrsA = range(1960,oob_yr)\n",
    "            yrsA = [ str(x) for x in yrsA]\n",
    "            yrsA = \",\".join(yrsA)\n",
    "            # create list of part of sequence after out of base year\n",
    "            yrsB = range((oob_yr+1),1991)\n",
    "            yrsB = [ str(x) for x in yrsB]\n",
    "            yrsB = \",\".join(yrsB)\n",
    "            # create data sequence ommiting out base year\n",
    "            cdo.selyear(yrsA,input='../data/'+region+'.basefile.nc',output='../data/basefileA.nc')\n",
    "            cdo.selyear(yrsB,input='../data/'+region+'.basefile.nc',output='../data/basefileB.nc')\n",
    "            cdo.mergetime(input='../data/basefileA.nc ../data/basefileB.nc',\n",
    "                          output='../data/basefile_samp.nc')\n",
    "            # select random year from within pruned base period\n",
    "            ryr = random.choice((yrsA+','+yrsB).split(','))\n",
    "            cdo.selyear(ryr,input='../data/basefile_samp.nc',output='../data/repyr.nc')\n",
    "            # label it as the missing year\n",
    "            cdo.setyear(oob_yr,input='../data/repyr.nc',output='../data/repyr.relab.nc')\n",
    "            # include duplicate year in the boot-strap base period\n",
    "            cdo.mergetime(input='../data/basefile_samp.nc ../data/repyr.relab.nc',\n",
    "                          output='../data/basefile_rebuilt.nc')\n",
    "            # calculate period max/min values over window, for constructing percentiles\n",
    "            cdo.ydrunmin(str(5),input='../data/basefile_rebuilt.nc',output='../data/minfile.nc')\n",
    "            cdo.ydrunmax(str(5),input='../data/basefile_rebuilt.nc',output='../data/maxfile.nc')\n",
    "            # adjust base period around years lost due to the windowed stats\n",
    "            yrs = range(1960,1989)\n",
    "            yrs = [ str(x) for x in yrs]\n",
    "            yrs = \",\".join(yrs)\n",
    "            cdo.selyear(yrs,input='../data/basefile_rebuilt.nc',output='../data/basefile.trim.nc')\n",
    "            # add extra days from following year so that can construct running stats\n",
    "            cdo.seldate('1989-01-01,1989-01-02',input='../data/basefile_rebuilt.nc',\n",
    "                        output='../data/extradays.nc')\n",
    "            cdo.mergetime(input='../data/basefile.trim.nc ../data/extradays.nc',\n",
    "                          output='../data/basefile.extnd.nc')\n",
    "            # calculate percentile \n",
    "            cdo.ydrunpctl('90,5',input='../data/basefile.extnd.nc ../data/minfile.nc ../data/maxfile.nc',\n",
    "                          output='../data/pctl90_'+str(oob_yr)+'.nc')\n",
    "            # sweep up\n",
    "            subprocess.call([\"rm\",\"../data/basefileA.nc\",\"../data/basefileB.nc\",\n",
    "                             \"../data/basefile_samp.nc\",\"../data/repyr.nc\",\"../data/repyr.relab.nc\",\n",
    "                             \"../data/basefile_rebuilt.nc\",\"../data/minfile.nc\",\"../data/maxfile.nc\",\n",
    "                             \"../data/basefile.trim.nc\",\"../data/extradays.nc\",\n",
    "                             \"../data/basefile.extnd.nc\"])\n",
    "        ## find mean estimate of percentile levels\n",
    "        # list of estimates\n",
    "        yrs = range(1961,1988)\n",
    "        fnames = [ '../data/pctl90_'+str(x)+'.nc' for x in yrs ]\n",
    "        fnames = \" \".join(fnames)\n",
    "        cdo.ensmean(input=fnames,output='../data/pctl90.nc')\n",
    "        # sweep up\n",
    "        proc_call = [\"rm\"]\n",
    "        proc_call.extend(fnames.split(' '))\n",
    "        subprocess.call(proc_call)\n",
    "        ## create long term percentile climatology file\n",
    "        cdo.setrtoc(\"-1000,1000,0\",\n",
    "                    input = \"../data/\"+region+\".max.daily.nc\",\n",
    "                    output=\"../data/fullnull.nc\")\n",
    "        cdo.add(input=\"../data/fullnull.nc ../data/pctl90.nc\",\n",
    "                output=\"../data/pctl90.extnd.nc\")\n",
    "        ## check each cell for > 90th percentile max temperature \n",
    "        cdo.gt(input = \"../data/\"+region+\".max.daily.nc ../data/pctl90.extnd.nc\", \n",
    "               output = \"../data/gt90.nc\")\n",
    "        ## Do windowed sum, so that grid cell has value of 6 if that date, 2 days \n",
    "        #  before and 3 days after are all 'true'\n",
    "        cdo.runsum(str(seq_length),input = \"../data/gt90.nc\", \n",
    "                   output = \"../data/eventsinwindow.nc\")\n",
    "        ## Check for events\n",
    "        cdo.gec(str(seq_length),\n",
    "                input = \"../data/eventsinwindow.nc\", \n",
    "                output = \"../data/prolongedevents.nc\")\n",
    "        ## Check for any events within region\n",
    "        #  NOTE: Since summing over a sliding window if a date is marked as an\n",
    "        #  event, then the 2 days before and 3 days after are also events\n",
    "        cdo.fldmax(input = \"../data/prolongedevents.nc\", \n",
    "                   output = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "        ## Sweep up\n",
    "        subprocess.call([\"rm\",\"../data/pctl90.nc\",\"../data/fullnull.nc\",\n",
    "                         \"../data/pctl90.extnd.nc\",\"../data/gt90.nc\",\"../data/eventsinwindow.nc\",\n",
    "                         \"../data/prolongedevents.nc\"])\n",
    "    #--- Generate time series data\n",
    "    # create variable from netcdf data\n",
    "    metrec = cdo.output(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # convert from unicode to integer\n",
    "    metrec = [int(x) for x in metrec]\n",
    "    # add values for dates omitted by windowed sum\n",
    "    for i in range(2) :\n",
    "        metrec.insert(0,int(0))\n",
    "    for i in range(3) :\n",
    "        metrec.insert(len(metrec),int(0))\n",
    "    # extend heatwave periods to account for windowed sum\n",
    "    tmp = metrec[:]\n",
    "    for i in range(2,(len(metrec)-1)) :\n",
    "        if ( metrec[i] == 1 ) & ( metrec[i-1] != 1 ) :\n",
    "            tmp[i-1] = 1 ; tmp[i-2] = 1\n",
    "        elif ( metrec[i] == 1 ) & ( metrec[i+1] != 1 ) :\n",
    "            tmp[i+1] = 1 ; tmp[i+2] = 1 ; tmp[i+3] = 1\n",
    "    metrec = tmp\n",
    "    # output dates (creates arrary of one long string)\n",
    "    dates = cdo.showdate(input = \"../data/eventrec.\"+deflab+\".\"+region+\".nc\")\n",
    "    # set each date as a seperate element\n",
    "    dates = dates[0].split()\n",
    "    # set as datestamp objects\n",
    "    dates = pd.to_datetime(dates)\n",
    "    # add 2 days to start of list (removed by windowed sum)\n",
    "    for i in range(2) :\n",
    "        day_alpha = dates[0] - Day()\n",
    "        dates = dates.insert(0,day_alpha)\n",
    "    # add 3 days to end of list (removed by windowed sum)\n",
    "    for i in range(3) :\n",
    "        day_omega = dates[len(dates)-1] + Day()\n",
    "        dates = dates.insert(len(dates),day_omega)\n",
    "    #--- returen time series data\n",
    "    ts = pd.Series(metrec, index=dates)\n",
    "    return ts\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
